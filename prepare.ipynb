{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4869d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duljina korpusa: 75,507,588 znakova\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "\n",
    "input_file_path = 'dataset/cmu_plots.txt'\n",
    "output_dir = \"dataset/processed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(f\"Duljina korpusa: {len(text):,} znakova\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "731db091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vokabular: 587 znakova\n"
     ]
    }
   ],
   "source": [
    "# Skup svih jedinstvenih znakova\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\"Vokabular: {vocab_size} znakova\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35875b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\x92', '\\xa0', '¡', '¢', '£', '¥', '¦', '«', '\\xad', '¯', '°', '²', '´', '»', '¼', '½', '¿', 'À', 'Á', 'Â', 'Ä', 'Å', 'Æ', 'Ç', 'È', 'É', 'Ê', 'Ë', 'Í', 'Î', 'Ñ', 'Ó', 'Ô', 'Ö', '×', 'Ø', 'Ú', 'Ü', 'Þ', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ð', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'Ā', 'ā', 'ă', 'ą', 'Ć', 'ć', 'Ċ', 'Č', 'č', 'Đ', 'đ', 'ē', 'ę', 'ě', 'ğ', 'ġ', 'Ħ', 'ĩ', 'ī', 'İ', 'ı', 'ĺ', 'Ł', 'ł', 'ń', 'ņ', 'ŋ', 'Ō', 'ō', 'ŏ', 'Ő', 'ő', 'œ', 'ř', 'Ś', 'ś', 'Ş', 'ş', 'Š', 'š', 'ţ', 'ť', 'ū', 'ŭ', 'ů', 'ű', 'ź', 'Ż', 'ż', 'Ž', 'ž', 'Ǝ', 'ư', 'ʼ', '˝', '̧', 'Α', 'Δ', 'Θ', 'Ο', 'ά', 'ή', 'λ', 'π', 'ό', 'А', 'Б', 'Г', 'Д', 'Е', 'Ж', 'З', 'И', 'Й', 'К', 'Л', 'М', 'Н', 'О', 'П', 'Р', 'С', 'Т', 'Ц', 'Ш', 'Щ', 'Ю', 'Я', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'х', 'ц', 'ч', 'ш', 'щ', 'ы', 'ь', 'я', 'ђ', 'ї', 'ј', 'њ', 'ה', 'ו', 'י', 'ך', 'ל', 'מ', 'ש', 'أ', 'ا', 'ب', 'ت', 'ح', 'س', 'ط', 'ف', 'ل', 'م', 'ن', 'و', 'ي', 'ँ', 'ं', 'अ', 'आ', 'इ', 'ई', 'उ', 'ए', 'ओ', 'औ', 'क', 'ख', 'ग', 'च', 'ज', 'ट', 'ड', 'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', 'श', 'स', 'ह', 'ा', 'ि', 'ी', 'ु', 'ू', 'े', 'ै', 'ो', '्', 'ট', 'ড', 'ব', 'ল', 'ি', 'ু', '্', 'ષ', 'அ', 'எ', 'ச', 'த', 'ந', 'ன', 'ப', 'ம', 'ய', 'ர', 'ற', 'ல', 'ா', 'ி', 'ு', 'ே', 'ை', 'ொ', '்', 'ം', 'ങ', 'ത', 'ദ', 'ധ', 'ന', 'പ', 'മ', 'യ', 'ര', 'റ', 'വ', 'ശ', 'സ', 'ാ', 'ി', 'ു', 'ൂ', 'ൃ', 'െ', 'ൊ', '്', 'ạ', 'ả', 'ế', 'ễ', 'ọ', 'ồ', 'ộ', 'ờ', 'ợ', 'ủ', 'ứ', '\\u200b', '\\u200d', '\\u200e', '‐', '‑', '–', '—', '―', '‘', '’', '“', '”', '„', '†', '•', '…', '′', '″', '₣', '₤', '₩', '€', '⅓', '⅞', '−', '♠', '♥', '♦', 'Ɑ', '\\u3000', '。', '『', '』', 'が', 'す', 'て', 'の', 'べ', 'ア', 'イ', 'カ', 'ト', 'ド', 'バ', 'ブ', 'ラ', 'ル', '・', 'ー', '䣨', '一', '三', '不', '之', '了', '五', '亦', '仁', '仙', '任', '個', '倫', '克', '公', '典', '勇', '半', '原', '和', '因', '図', '塔', '士', '夏', '大', '奇', '妃', '妹', '姉', '姦', '子', '孝', '宍', '寫', '小', '山', '巴', '希', '平', '幹', '张', '彧', '德', '忠', '愛', '憂', '懼', '手', '摩', '改', '新', '早', '旭', '是', '月', '望', '格', '次', '歌', '正', '炳', '無', '王', '玩', '珍', '珠', '生', '田', '目', '相', '矣', '研', '碟', '社', '究', '続', '老', '者', '而', '能', '若', '英', '荷', '萊', '落', '蘭', '要', '見', '話', '諾', '謂', '賽', '赤', '赵', '超', '辞', '辻', '這', '速', '連', '過', '道', '遠', '郎', '部', '都', '長', '離', '電', '頭', '首', '高', '겨', '늦', '레', '미', '서', '안', '어', '영', '한', '해', '화', 'ﬁ', '\\ufeff', '（', '）', '，', '�']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df9b21f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfabetski znakovi: 455 (77.5%)\n",
      "Numerički znakovi: 18 (3.1%)\n",
      "Interpunkcija: 32 (5.5%)\n",
      "Razmaci: 4 (0.7%)\n",
      "Ostali znakovi: 81 (13.8%)\n",
      "\n",
      "Prvih 20 alfabetskih: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T']\n",
      "Svi numerički: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '²', '¼', '½', '⅓', '⅞', '一', '三', '五']\n",
      "Prvih 20 interpunkcijskih: ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>']\n",
      "Svi razmaci (repr): [\"'\\\\n'\", \"' '\", \"'\\\\xa0'\", \"'\\\\u3000'\"]\n",
      "Prvih 30 ostalih: ['\\x92', '¡', '¢', '£', '¥', '¦', '«', '\\xad', '¯', '°', '´', '»', '¿', '×', '˝', '̧', 'ँ', 'ं', 'ा', 'ि', 'ी', 'ु', 'ू', 'े', 'ै', 'ो', '्', 'ি', 'ু', '্']\n"
     ]
    }
   ],
   "source": [
    "# Analiza vokabulara\n",
    "import string\n",
    "import unicodedata\n",
    "\n",
    "alphabetic = [c for c in chars if c.isalpha()]\n",
    "numeric = [c for c in chars if c.isnumeric()]\n",
    "punctuation = [c for c in chars if c in string.punctuation]\n",
    "whitespace = [c for c in chars if c.isspace()]\n",
    "other = [c for c in chars if not (c.isalpha() or c.isnumeric() or c in string.punctuation or c.isspace())]\n",
    "\n",
    "print(f\"Alfabetski znakovi: {len(alphabetic)} ({len(alphabetic)/len(chars)*100:.1f}%)\")\n",
    "print(f\"Numerički znakovi: {len(numeric)} ({len(numeric)/len(chars)*100:.1f}%)\")\n",
    "print(f\"Interpunkcija: {len(punctuation)} ({len(punctuation)/len(chars)*100:.1f}%)\")\n",
    "print(f\"Razmaci: {len(whitespace)} ({len(whitespace)/len(chars)*100:.1f}%)\")\n",
    "print(f\"Ostali znakovi: {len(other)} ({len(other)/len(chars)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPrvih 20 alfabetskih: {alphabetic[:20]}\")\n",
    "print(f\"Svi numerički: {numeric}\")\n",
    "print(f\"Prvih 20 interpunkcijskih: {punctuation[:20]}\")\n",
    "print(f\"Svi razmaci (repr): {[repr(c) for c in whitespace]}\")\n",
    "print(f\"Prvih 30 ostalih: {other[:30]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfabf644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukupno tokena: 16,661,114\n"
     ]
    }
   ],
   "source": [
    "# Tokenizacija teksta\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "ids = enc.encode(text)\n",
    "print(f\"Ukupno tokena: {len(ids):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9fa8a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2484, 306, 21862, 11, 257, 1327, 12, 16090, 17536, 4639, 290, 9334, 418, 3099, 11, 257, 46909, 48982, 396, 11]\n",
      "Shlykov, a hard-working taxi driver and Lyosha, a saxophonist,\n"
     ]
    }
   ],
   "source": [
    "print(ids[:20])\n",
    "print(enc.decode(ids[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e25662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiktoken GPT-2 vokabular: 50,257 tokena\n",
      "\n",
      "Najčešći tokeni:\n",
      "Token 11: ',' -> 738,159 puta\n",
      "Token 262: ' the' -> 736,100 puta\n",
      "Token 13: '.' -> 655,506 puta\n",
      "Token 284: ' to' -> 478,402 puta\n",
      "Token 290: ' and' -> 455,337 puta\n",
      "Token 257: ' a' -> 362,907 puta\n",
      "Token 286: ' of' -> 261,135 puta\n",
      "Token 318: ' is' -> 224,176 puta\n",
      "Token 287: ' in' -> 201,670 puta\n",
      "Token 465: ' his' -> 190,688 puta\n",
      "Token 607: ' her' -> 148,273 puta\n",
      "Token 338: ''s' -> 145,131 puta\n",
      "Token 339: ' he' -> 140,012 puta\n",
      "Token 326: ' that' -> 137,095 puta\n",
      "Token 351: ' with' -> 134,778 puta\n",
      "Token 683: ' him' -> 96,938 puta\n",
      "Token 329: ' for' -> 93,884 puta\n",
      "Token 416: ' by' -> 91,253 puta\n",
      "Token 12: '-' -> 84,094 puta\n",
      "Token 319: ' on' -> 77,868 puta\n",
      "\n",
      "Najrijeđi tokeni:\n",
      "Token 46968: ' convol' -> 1 puta\n",
      "Token 30228: 'Personal' -> 1 puta\n",
      "Token 39814: 'olulu' -> 1 puta\n",
      "Token 43720: ' rand' -> 1 puta\n",
      "Token 41570: 'forestation' -> 1 puta\n",
      "Token 41752: ' PASS' -> 1 puta\n",
      "Token 40744: 'Manchester' -> 1 puta\n",
      "Token 29050: ' exported' -> 1 puta\n",
      "Token 44808: '00007' -> 1 puta\n",
      "Token 44110: ' Traps' -> 1 puta\n",
      "Token 20031: 'RP' -> 1 puta\n",
      "Token 7655: ' WH' -> 1 puta\n",
      "Token 39988: ' Diseases' -> 1 puta\n",
      "Token 17209: 'tm' -> 1 puta\n",
      "Token 26959: 'Science' -> 1 puta\n",
      "Token 11052: ' Value' -> 1 puta\n",
      "Token 21010: ' Biden' -> 1 puta\n",
      "Token 28614: ' supra' -> 1 puta\n",
      "Token 44513: ' SECTION' -> 1 puta\n",
      "Token 31850: ' estimation' -> 1 puta\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tiktoken GPT-2 vokabular: {enc.n_vocab:,} tokena\")\n",
    "\n",
    "# Najčešći tokeni\n",
    "from collections import Counter\n",
    "token_counts = Counter(ids)\n",
    "most_common = token_counts.most_common(20)\n",
    "least_common = token_counts.most_common()[-20:]\n",
    "\n",
    "print(\"\\nNajčešći tokeni:\")\n",
    "for token_id, count in most_common:\n",
    "    token_str = enc.decode([token_id])\n",
    "    print(f\"Token {token_id}: '{token_str}' -> {count:,} puta\")\n",
    "\n",
    "print(\"\\nNajrijeđi tokeni:\")\n",
    "for token_id, count in least_common:\n",
    "    token_str = enc.decode([token_id])\n",
    "    print(f\"Token {token_id}: '{token_str}' -> {count:,} puta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3ba51c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizacija završena i spremljena.\n"
     ]
    }
   ],
   "source": [
    "n = len(ids)\n",
    "train_ids = np.array(ids[:int(n * 0.9)], dtype=np.uint16)\n",
    "val_ids = np.array(ids[int(n * 0.9):], dtype=np.uint16)\n",
    "\n",
    "train_ids.tofile(os.path.join(output_dir, \"train.bin\"))\n",
    "val_ids.tofile(os.path.join(output_dir, \"val.bin\"))\n",
    "\n",
    "print(\"Tokenizacija završena i spremljena.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plot-generator-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
